
@article{Sereshkeh2017,
author = {Sereshkeh, Alborz Rezazadeh and Trott, Robert and Bricout, Aur{\'{e}}lien and Chau, Tom},
doi = {10.1142/S0129065717500332},
file = {:home/demetres/Downloads/Online EEG Classification of Covert Speech for Brain-Computer Interfacing.pdf:pdf},
issn = {0129-0657},
journal = {International Journal of Neural Systems},
keywords = {autoregressive model,brain,computer interface,covert speech,eeg,support vector machine},
number = {8},
pages = {1750033},
title = {{Online EEG Classification of Covert Speech for Brain–Computer Interfacing}},

volume = {27},
year = {2017}
}
@book{Dunn97,
address = {Circle Pines, Minnesota},
author = {Dunn, L M},
edition = {3},
publisher = {American Guidance Service},
title = {{Peabody Picture Vocabulary Test, third edition}},
year = {1997}
}

@book{EVT,
address = {Circle Pines, MN},
author = {Williams, K T},
publisher = {American Guidance Service},
title = {{Expressive Vocabulary Test}},
year = {1997}
}
@book{GoodfellowTextbook,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}
@book{GuentherBook,
 ISBN = {9780262034715},
 abstract = {<p>In this book, Frank Guenther offers a comprehensive, unified account of the neural computations underlying speech production, with an emphasis on speech motor control rather than linguistic content. Guenther focuses on the brain mechanisms responsible for commanding the musculature of the vocal tract to produce articulations that result in an acoustic signal conveying a desired string of syllables. Guenther provides neuroanatomical and neurophysiological descriptions of the primary brain structures involved in speech production, looking particularly at the cerebral cortex and its interactions with the cerebellum and basal ganglia, using basic concepts of control theory (accompanied by nontechnical explanations) to explore the computations performed by these brain regions.Guenther offers a detailed theoretical framework to account for a broad range of both behavioral and neurological data on the production of speech. He discusses such topics as the goals of the neural controller of speech; neural mechanisms involved in producing both short and long utterances; and disorders of the speech system, including apraxia of speech and stuttering. Offering a bridge between the neurological and behavioral literatures on speech production, the book will be a valuable resource for researchers in both fields.</p>},
 author = {Frank H. Guenther},
 publisher = {MIT Press},
 title = {Neural Control of Speech},
 year = {2016}
}
@book{GravesRNNBook,
  Author = {Alex Graves},
  Title = {Supervised Sequence Labelling with Recurrent Neural Networks (Studies in Computational Intelligence)},
  Publisher = {Springer},
  Year = {2012},
  ISBN = {3642247962},
  URL = {https://www.cs.toronto.edu/~graves/preprint.pdf}
}
@book{ElectricFieldsOfTheBrain_ch5and6,
  added-at = {2013-01-19T22:44:22.000+0100},
  address = {New York, NY},
  author = {Nunez, P. L. and Srinivasan, R.},
  biburl = {https://www.bibsonomy.org/bibtex/2f1d8dcacfd90852f10dd3624cc7b74b2/lantiq},
  groups = {public},
  interhash = {b8bb0878237a11f8d9ca13a869c6170b},
  intrahash = {f1d8dcacfd90852f10dd3624cc7b74b2},
  keywords = {neuroscience EEG},
  publisher = {Oxford University Press},
  timestamp = {2013-01-19T22:44:22.000+0100},
  title = {Electric Fields of the Brain: The Neurophysics of {EEG}},
  username = {lantiq},
  year = 2006
}
@inproceedings{Eyben13-RDI,
  author = {Florian Eyben and Felix Weninger and Florian Gross and Bj\"orn Schuller},
  title = {Recent developments in {openSMILE}, the {M}unich Open-Source Multimedia Feature Extractor},
  booktitle = {Proc.\ of ACM Multimedia 2013},
  year = {2013},
  address = {Barcelona, Spain},
  pages = {835--838},
  publisher = {ACM},
}


@article{Delorme04eeglab,
    author = {Arnaud Delorme and Scott Makeig},
    title = {{EEGLAB}: {A}n open source toolbox for analysis of single-trial {EEG} dynamics including independent component analysis},
    journal = {Journal of Neuroscience Methods},
    year = {2004},
    volume = {134},
    pages = {9--21}
}
@article{Guimaraes2007,
 author={M.P. Guimaraes and D.K. Wong and E.T. Uy and L. Grosenick and P. Suppes},
 journal={Biomedical Engineering, IEEE Transactions on},
 title={Single-Trial Classification of {MEG} Recordings},
 year={2007},
 month={March},
 volume={54},
 number={3},
 pages={436-443},
 doi={10.1109/TBME.2006.888824},
 ISSN={0018-9294},
}
@INPROCEEDINGS{eog, 
author={C. Guerrero-Mosquera and A. N. Vazquez}, 
booktitle={2009 17th European Signal Processing Conference}, 
title={Automatic removal of ocular artifacts from EEG data using adaptive filtering and Independent Component Analysis}, 
year={2009}, 
pages={2317-2321}, 
keywords={adaptive filters;electroencephalography;feature extraction;independent component analysis;least squares approximations;medical signal processing;EEG components;EEG data;ICA;RLS algorithm;adaptive filtering;brain waves;horizontal eye movements;independent component analysis;interference estimation;ocular artifacts automatic removal;online interference cancellation;recursive least squares;reference signal extraction;vertical eye movements;Abstracts;Electroencephalography}, 
month={Aug},}
@article{Tang2013a,
  author    = {Yichuan Tang},
  title     = {Deep Learning using Support Vector Machines},
  journal   = {CoRR},
  volume    = {abs/1306.0239},
  year      = {2013},
  url       = {http://arxiv.org/abs/1306.0239},
  archivePrefix = {arXiv},
  eprint    = {1306.0239},
  timestamp = {Wed, 07 Jun 2017 14:41:28 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/Tang13},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Szegedy2015,
  author    = {Sergey Ioffe and
               Christian Szegedy},
  title     = {Batch Normalization: Accelerating Deep Network Training by Reducing
               Internal Covariate Shift},
  journal   = {CoRR},
  volume    = {abs/1502.03167},
  year      = {2015},
  url       = {http://arxiv.org/abs/1502.03167},
  archivePrefix = {arXiv},
  eprint    = {1502.03167},
  timestamp = {Wed, 07 Jun 2017 14:40:49 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/IoffeS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Sønderby2015,
abstract = {Machine learning is widely used to analyze biological sequence data. Non-sequential models such as SVMs or feed-forward neural networks are often used although they have no natural way of handling sequences of varying length. Recurrent neural networks such as the long short term memory (LSTM) model on the other hand are designed to handle sequences. In this study we demonstrate that LSTM networks predict the subcellular location of proteins given only the protein sequence with high accuracy (0.902) outperforming current state of the art algorithms. We further improve the performance by introducing convolutional filters and experiment with an attention mechanism which lets the LSTM focus on specific parts of the protein. Lastly we introduce new visualizations of both the convolutional filters and the attention mechanisms and show how they can be used to extract biological relevant knowledge from the LSTM networks.},
archivePrefix = {arXiv},
arxivId = {1503.01919},
author = {S{\o}nderby, S{\o}ren Kaae and S{\o}nderby, Casper Kaae and Nielsen, Henrik and Winther, Ole},
doi = {10.1007/978-3-319-21233-3_6},
eprint = {1503.01919},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/S{\o}nderby et al. - 2015 - Convolutional LSTM Networks for Subcellular Localization of Proteins.pdf:pdf},
isbn = {9783319212326},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Convolutional networks,Deep learning,LSTM,Machine learning,Neural networks,RNN,Subcellular location},
month = {mar},
pages = {68--80},
title = {{Convolutional LSTM Networks for Subcellular Localization of Proteins}},
url = {https://arxiv.org/pdf/1503.01919.pdf http://arxiv.org/abs/1503.01919 http://dx.doi.org/10.1007/978-3-319-21233-3{\_}6},
volume = {9199},
year = {2015}
}
@article{Tourville2011,
abstract = {The DIVA model of speech production provides a computationally and neuroanatomically explicit account of the network of brain regions involved in speech acquisition and production. An overview of the model is provided along with descriptions of the computations performed in the different brain regions represented in the model. The latest version of the model, which contains a new right-lateralised feedback control map in ventral premotor cortex, will be described, and experimental results that motivated this new model component will be discussed. Application of the model to the study and treatment of communication disorders will also be briefly described.},
author = {Tourville, Jason A and Guenther, Frank H},
doi = {10.1080/01690960903498424},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tourville, Guenther - Unknown - The DIVA model A neural theory of speech acquisition and production.pdf:pdf},
issn = {0169-0965},
journal = {Language and Cognitive Processes},
keywords = {Computational modeling,DIVA model,Functional magnetic resonance imaging,Motor learning,Speech production},
month = {aug},
number = {7},
pages = {952--981},
title = {{The DIVA model: A neural theory of speech acquisition and production}},
volume = {26},
year = {2011}
}
@article{Tangermann2012,
abstract = {The BCI competition IV stands in the tradition of prior BCI competitions that aim to provide high quality neuroscientific data for open access to the scientific community. As experienced already in prior competitions not only scientists from the narrow field of BCI compete, but scholars with a broad variety of backgrounds and nationalities. They include high specialists as well as students. The goals of all BCI competitions have always been to challenge with respect to novel paradigms and complex data. We report on the following challenges: (1) asynchronous data, (2) synthetic, (3) multi-class continuous data, (4) session-to-session transfer, (5) directionally modulated MEG, (6) finger movements recorded by ECoG. As after past competitions, our hope is that winning entries may enhance the analysis methods of future BCIs.},
author = {Tangermann, Michael and M{\"{u}}ller, Klaus Robert and Aertsen, Ad and Birbaumer, Niels and Braun, Christoph and Brunner, Clemens and Leeb, Robert and Mehring, Carsten and Miller, Kai J. and M{\"{u}}ller-Putz, Gernot R. and Nolte, Guido and Pfurtscheller, Gert and Preissl, Hubert and Schalk, Gerwin and Schl{\"{o}}gl, Alois and Vidaurre, Carmen and Waldert, Stephan and Blankertz, Benjamin},
doi = {10.3389/fnins.2012.00055},
file = {:home/demetres/Downloads/fnins-06-00055.pdf:pdf},
isbn = {1662-453X},
issn = {16624548},
journal = {Frontiers in Neuroscience},
keywords = {Bci,Brain-computer interface,Competition},
number = {JULY},
pages = {1--31},
pmid = {22811657},
title = {{Review of the BCI competition IV}},
volume = {6},
year = {2012}
}
@article{Rivet2009,
abstract = {A brain-computer interface (BCI) is a communication system that allows to control a computer or any other device thanks to the brain activity. The BCI described in this paper is based on the P300 speller BCI paradigm introduced by Farwell and Donchin . An unsupervised algorithm is proposed to enhance P300 evoked potentials by estimating spatial filters; the raw EEG signals are then projected into the estimated signal subspace. Data recorded on three subjects were used to evaluate the proposed method. The results, which are presented using a Bayesian linear discriminant analysis classifier , show that the proposed method is efficient and accurate.},
author = {Rivet, Bertrand and Souloumiac, Antoine and Attina, Virginie and Gibert, Guillaume},
doi = {10.1109/TBME.2009.2012869},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rivet et al. - 2009 - xDAWN Algorithm to Enhance Evoked Potentials Application to Brain–Computer Interface.pdf:pdf},
isbn = {0018-9294},
issn = {15582531},
journal = {IEEE Transactions on Biomedical Engineering},
keywords = {Brain-computer interface (BCI),P300 speller,spatial enhancement,xDAWN algorithm},
number = {8},
pages = {2035--2043},
pmid = {19174332},
title = {{xDAWN Algorithm to Enhance Evoked Potentials: Application to Brain-Computer Interface}},
volume = {56},
year = {2009}
}
@article{RezaeiTabar2016,
abstract = {Brain Computer Interface (BCI) systems provide control of external devices by using only brain activity. In recent years, there has been a great interest in developing BCI systems for different applications. These systems are capable of solving daily life problems for both healthy and disabled people. One of the most important applications of BCI is to provide communication for disabled people that are totally paralysed. In this paper, different parts of a BCI system and different methods used in each part are reviewed. Neuroimaging devices, with an emphasis on EEG (electroencephalography), are presented and brain activities as well as signal processing methods used in EEG-based BCIs are explained in detail. Current methods and paradigms in BCI based speech communication are considered.},
author = {{Rezaei Tabar}, Yousef and Halici, Ugur},
doi = {10.1017/S1062798716000569},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Brain Computer Interfaces for Silent Speech.pdf:pdf},
isbn = {1062798716},
issn = {1062-7987},
journal = {European Review},
number = {02},
pages = {208--230},
title = {{Brain Computer Interfaces for Silent Speech}},
volume = {25},
year = {2016}
}
@article{Demsar2006,
abstract = {While methods for comparing two learning algorithms on a single data set have been scrutinized for quite some time already, the issue of statistical tests for comparisons of more algorithms on multiple data sets, which is even more essential to typical machine learning studies, has been all but ignored. This article reviews the current practice and then theoretically and empirically examines several suitable tests. Based on that, we recommend a set of simple, yet safe and robust non-parametric tests for statistical comparisons of classifiers: the Wilcoxon signed ranks test for comparison of two classifiers and the Friedman test with the corresponding post-hoc tests for comparison of more classifiers over multiple data sets. Results of the latter can also be neatly presented with the newly introduced CD (critical difference) diagrams.},
annote = {For comparing two classifiers in in cross-validation, use: Wilcoxon Signed Rank Test.

For comparing multiple classifiers xval:},
author = {Dem{\v{s}}ar, Janez},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dem{\v{s}}ar - 2006 - Statistical Comparisons of Classifiers over Multiple Data Sets.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {Friedman test,Wilcoxon signed ranks test,comparative studies,multiple comparisons tests,statistical methods},
pages = {1--30},
title = {{Statistical Comparisons of Classifiers over Multiple Data Sets}},
volume = {7},
year = {2006}
}
@article{Srivastava2014,
abstract = {Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different " thinned " networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves the performance of neural networks on supervised learning tasks in vision, speech recognition, document classification and computational biology, obtaining state-of-the-art results on many benchmark data sets.},
annote = {Read the Appendices for value recommendations},
author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Srivastava et al. - 2014 - Dropout A Simple Way to Prevent Neural Networks from Overfitting.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {deep learning,model combination,neural networks,regularization},
pages = {1929--1958},
title = {{Dropout: A Simple Way to Prevent Neural Networks from Overfitting}},
volume = {15},
year = {2014}
}
@article{Zafar2017,
abstract = {Electroencephalogram (EEG)-based decoding human brain activity is challenging, owing to the low spatial resolution of EEG. However, EEG is an important technique, especially for brain–computer interface applications. In this study, a novel algorithm is proposed to decode brain activity associated with different types of images. In this hybrid algorithm, convolu-tional neural network is modified for the extraction of features, a t-test is used for the selec-tion of significant features and likelihood ratio-based score fusion is used for the prediction of brain activity. The proposed algorithm takes input data from multichannel EEG time-series, which is also known as multivariate pattern analysis. Comprehensive analysis was conducted using data from 30 participants. The results from the proposed method are com-pared with current recognized feature extraction and classification/prediction techniques. The wavelet transform-support vector machine method is the most popular currently used feature extraction and prediction method. This method showed an accuracy of 65.7{\%}. How-ever, the proposed method predicts the novel data with improved accuracy of 79.9{\%}. In con-clusion, the proposed algorithm outperformed the current feature extraction and prediction method.},
author = {Zafar, Raheel and Dass, Sarat C and Malik, Aamir Saeed},
doi = {10.1371/journal.pone.0178410},
isbn = {1111111111},
issn = {19326203},
journal = {PLoS ONE},
number = {5},
title = {{Electroencephalogram-based decoding cognitive states using convolutional neural network and likelihood ratio based score fusion}},
volume = {12},
year = {2017}
}
@article{Hochreiter1997a,
abstract = {Learning to store information over extended time intervals via recurrent backpropagation takes a very long time, mostly due to insuucient, decaying error back We brieey review Hochreiter's 1991 analysis of this problem, then address it by introducing a novel, eecient, gradient-based method called $\backslash$Long Short-Term Memory" (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete time steps by enforcing constant error through $\backslash$constant error carrousels" within special units. Multiplicative gate units learn to open and close access to the constant error LSTM is local in space and time; its computational complexity per time step and weight is O(1). Our experiments with artiicial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with RTRL, BPTT, Recurrent Cascade-Correlation, Elman nets, and Neural Sequence Chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artiicial long time lag tasks that have never been solved by previous recurrent network algorithms.},
archivePrefix = {arXiv},
arxivId = {1206.2944},
author = {Hochreiter, Sepp and {Urgen Schmidhuber}, Jj},
doi = {10.1162/neco.1997.9.8.1735},
eprint = {1206.2944},
isbn = {08997667 (ISSN)},
issn = {0899-7667},
journal = {Neural Computation},
number = {8},
pages = {1735--1780},
pmid = {9377276},
title = {{Long Short-Term Memory}},
url = {http://www7.informatik.tu-muenchen.de/{~}hochreit http://www.idsia.ch/{~}juergen http://www7.informatik.tu-muenchen.de/{~}hochreit{\%}5Cnhttp://www.idsia.ch/{~}juergen},
volume = {9},
year = {1997}
}
@article{Guenther2005,
abstract = {This paper describes a neural model of speech acquisition and production that accounts for a wide range of acoustic, kinematic, and neuroimaging data concerning the control of speech movements. The model is a neural network whose components correspond to regions of the cerebral cortex and cerebellum, including premotor, motor, auditory, and somatosensory cortical areas. Computer simulations of the model verify its ability to account for compensation to lip and jaw perturbations during speech. Specific anatom-ical locations of the model{\~{O}}s components are estimated, and these estimates are used to simulate fMRI experiments of simple syllable production.},
author = {Guenther, Frank H and Ghosh, Satrajit S and Tourville, Jason A},
doi = {10.1016/j.bandl.2005.06.001},
issn = {0093934X},
journal = {Brain and Language},
keywords = {Broca{\~{O}}s area,Model,Motor cortex,Neural transmission delays,Premotor cortex,Sensorimotor learning,Speech acquisition,Speech production,fMRI},
month = {mar},
number = {3},
pages = {280--301},
title = {{Neural modeling and imaging of the cortical interactions underlying syllable production}},
volume = {96},
year = {2006}
}
@article{Bouchard2013a,
abstract = {Speaking is one of the most complex actions that we perform, but nearly all of us learn to do it effortlessly. Production of fluent speech requires the precise, coordinated movement of multiple articulators (for example, the lips, jaw, tongue and larynx) over rapid time scales. Here we used high-resolution, multi-electrode cortical recordings during the production of consonant-vowel syllables to determine the organization of speech sensorimotor cortex in humans. We found speech-articulator representations that are arranged somatotopically on ventral pre-and post-central gyri, and that partially overlap at individual electrodes. These representations were coordinated temporally as sequences during syllable production. Spatial patterns of cortical activity showed an emergent, population-level representation, which was orga-nized by phonetic features. Over tens of milliseconds, the spatial patterns transitioned between distinct representations for different consonants and vowels. These results reveal the dynamic organization of speech sensorimotor cortex during the generation of multi-articulator movements that underlies our ability to speak. Speech communication critically depends on the ability to produce the large number of sounds that compose a given language 1,2 . The wide range of spoken sounds results from highly flexible configura-tions of the vocal tract, which filters sound produced at the larynx through movements of the lips, jaw and tongue that are coordi-nated precisely 3–5 . Each articulator has extensive degrees of freedom, making a large number of different speech movements possible. How humans exert such precise control despite the wide variety of move-ment possibilities is a central unanswered question 1,6,7 . The cortical control of articulation is mediated primarily by the ventral half of the lateral sensorimotor (Rolandic) cortex (ventral sensorimotor cortex, vSMC) 8–10 , which provides corticobulbar pro-jections to, and afferent innervation from, the face and vocal tract (Fig. 1a, b) 11,12},
author = {Bouchard, Kristofer E and Mesgarani, Nima and Johnson, Keith and Chang, Edward F},
doi = {10.1038/nature11911},
issn = {0028-0836},
journal = {Nature},
month = {mar},
number = {7441},
pages = {327--332},
title = {{Functional organization of human sensorimotor cortex for speech articulation}},
volume = {495},
year = {2013}
}
@article{Luong2015,
abstract = {An attentional mechanism has lately been used to improve neural machine translation (NMT) by selectively focusing on parts of the source sentence during translation. However, there has been little work exploring useful architectures for attention-based NMT. This paper examines two simple and effective classes of attentional mechanism: a global approach which always attends to all source words and a local one that only looks at a subset of source words at a time. We demonstrate the effectiveness of both approaches over the WMT translation tasks between English and German in both directions. With local attention, we achieve a significant gain of 5.0 BLEU points over non-attentional systems which already incorporate known techniques such as dropout. Our ensemble model using different attention architectures has established a new state-of-the-art result in the WMT'15 English to German translation task with 25.9 BLEU points, an improvement of 1.0 BLEU points over the existing best system backed by NMT and an n-gram reranker.},
archivePrefix = {arXiv},
arxivId = {1508.04025},
author = {Luong, Minh-Thang and Pham, Hieu and Manning, Christopher D},
doi = {10.18653/v1/D15-1166},
eprint = {1508.04025},
isbn = {9781941643327},
issn = {10495258},
keywords = {()},
pmid = {14527267},
title = {{Effective Approaches to Attention-based Neural Machine Translation}},
url = {https://arxiv.org/pdf/1508.04025.pdf},
year = {2015}
}
@article{Fries2015,
abstract = {I propose that synchronization affects communication between neuronal groups. Gamma-band (30-90 Hz) synchronization modulates excitation rapidly enough that it escapes the following inhibition and activates postsynaptic neurons effectively. Synchronization also ensures that a presynaptic activation pattern arrives at postsynaptic neurons in a temporally coordinated manner. At a postsynaptic neuron, multiple presynaptic groups converge, e.g., representing different stimuli. If a stimulus is selected by attention, its neuronal representation shows stronger and higher-frequency gamma-band synchronization. Thereby, the attended stimulus representation selectively entrains postsynaptic neurons. The entrainment creates sequences of short excitation and longer inhibition that are coordinated between pre- and postsynaptic groups to transmit the attended representation and shut out competing inputs. The predominantly bottom-up-directed gamma-band influences are controlled by predominantly top-down-directed alpha-beta-band (8-20 Hz) influences. Attention itself samples stimuli at a 7-8 Hz theta rhythm. Thus, several rhythms and their interplay render neuronal communication effective, precise, and selective.},
annote = {NULL},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Fries, Pascal},
doi = {10.1016/j.neuron.2015.09.034},
eprint = {15334406},
isbn = {http://dx.doi.org/10.1016/j.neuron.2015.09.034},
issn = {10974199},
journal = {Neuron},
number = {1},
pages = {220--235},
pmid = {26447583},
publisher = {Elsevier Inc.},
title = {{Rhythms for Cognition: Communication through Coherence}},
url = {http://dx.doi.org/10.1016/j.neuron.2015.09.034},
volume = {88},
year = {2015}
}
@article{Schultz2017,
author = {Schultz, Tanja and Wand, Michael and Hueber, Thomas and Krusienski, Dean J. and Herff, Christian and Brumberg, Jonathan S.},
doi = {10.1109/TASLP.2017.2752365},
issn = {2329-9290},
journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
number = {12},
pages = {2257--2271},
title = {{Biosignal-Based Spoken Communication: A Survey}},
volume = {25},
year = {2017}
}
@article{Sun,
abstract = {Prediction of memory performance (remembered or forgotten) has various potential applica-tions not only for knowledge learning but also for disease diagnosis. Recently, subsequent memory effects (SMEs)—the statistical differences in electroencephalography (EEG) sig-nals before or during learning between subsequently remembered and forgotten events— have been found. This finding indicates that EEG signals convey the information relevant to memory performance. In this paper, based on SMEs we propose a computational approach to predict memory performance of an event from EEG signals. We devise a convolutional neural network for EEG, called ConvEEGNN, to predict subsequently remembered and for-gotten events from EEG recorded during memory process. With the ConvEEGNN, predic-tion of memory performance can be achieved by integrating two main stages: feature extraction and classification. To verify the proposed approach, we employ an auditory mem-ory task to collect EEG signals from scalp electrodes. For ConvEEGNN, the average predic-tion accuracy was 72.07{\%} by using EEG data from pre-stimulus and during-stimulus periods, outperforming other approaches. It was observed that signals from pre-stimulus period and those from during-stimulus period had comparable contributions to memory per-formance. Furthermore, the connection weights of ConvEEGNN network can reveal promi-nent channels, which are consistent with the distribution of SME studied previously.},
author = {Sun, Xuyun and Qian, Cunle and Chen, Zhongqin and Wu, Zhaohui and Luo, Benyan and Pan, Gang},
doi = {10.1371/journal.pone.0167497},
issn = {19326203},
journal = {PLoS ONE},
number = {12},
title = {{Remembered or forgotten?-An EEG-Based computational prediction approach}},
volume = {11},
year = {2016}
}
@article{XuKELVINXU,
abstract = {Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-the-art performance on three benchmark datasets: Flickr8k, Flickr30k and MS COCO.},
archivePrefix = {arXiv},
arxivId = {1502.03044},
author = {Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhutdinov, Ruslan and Zemel, Richard and Bengio, Yoshua},
doi = {10.1109/72.279181},
eprint = {1502.03044},
isbn = {1045-9227 VO - 5},
issn = {19410093},
pmid = {18267787},
title = {{Show, Attend and Tell: Neural Image Caption Generation with Visual Attention}},
url = {https://arxiv.org/pdf/1502.03044.pdf},
year = {2015}
}
@article{Nakasaki1989,
abstract = {Following the discovery of context-dependent synchronization of oscillatory neuronal responses in the visual system, the role of neural synchrony in cortical networks has been expanded to provide a general mechanism for the coordination of distributed neural activity patterns. In the current paper, we present an update of the status of this hypothesis through summarizing recent results from our laboratory that suggest important new insights regarding the mechanisms, function and relevance of this phenomenon. In the fi rst part, we present recent results derived from animal experiments and mathematical simulations that provide novel explanations and mechanisms for zero and nero-zero phase lag synchronization. In the second part, we shall discuss the role of neural synchrony for expectancy during perceptual organization and its role in conscious experience. This will be followed by evidence that indicates that in addition to supporting conscious cognition, neural synchrony is abnormal in major brain disorders, such as schizophrenia and autism spectrum disorders. We conclude this paper with suggestions for further research as well as with critical issues that need to be addressed in future studies.},
annote = {NULL},
author = {Uhlhaas, Peter},
doi = {10.3389/neuro.07.017.2009},
isbn = {1662-5145 (Electronic)},
issn = {16625145},
journal = {Frontiers in Integrative Neuroscience},
keywords = {cognition,cortex,gamma,oscillations,synchrony},
number = {13},
pages = {3662--3669},
pmid = {2659167},
title = {{Neural synchrony in cortical networks: history, concept and current status}},
volume = {3},
year = {2009}
}
@article{KaiKengAng2008,
abstract = {In motor imagery-based brain computer interfaces (BCI), discriminative patterns can be extracted from the electroencephalogram (EEG) using the common spatial pattern (CSP) algorithm. However, the performance of this spatial filter depends on the operational frequency band of the EEG. Thus, setting a broad frequency range, or manually selecting a subject-specific frequency range, are commonly used with the CSP algorithm. To address this problem, this paper proposes a novel filter bank common spatial pattern (FBCSP) to perform autonomous selection of key temporal-spatial discriminative EEG characteristics. After the EEG measurements have been bandpass-filtered into multiple frequency bands, CSP features are extracted from each of these bands. A feature selection algorithm is then used to automatically select discriminative pairs of frequency bands and corresponding CSP features. A classification algorithm is subsequently used to classify the CSP features. A study is conducted to assess the performance of a selection of feature selection and classification algorithms for use with the FBCSP. Extensive experimental results are presented on a publicly available dataset as well as data collected from healthy subjects and unilaterally paralyzed stroke patients. The results show that FBCSP, using a particular combination feature selection and classification algorithm, yields relatively higher cross-validation accuracies compared to prevailing approaches.},
author = {{Kai Keng Ang} and {Zheng Yang Chin} and {Haihong Zhang} and {Cuntai Guan}},
doi = {10.1109/IJCNN.2008.4634130},
isbn = {978-1-4244-1820-6},
issn = {1098-7576},
journal = {2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)},
keywords = {Brain computer interfaces,CSP algorithm,Classification algorithms,Communication system control,EEG,Electroencephalography,Feature extraction,Filter bank,Finite impulse response filter,Frequency measurement,Fuses,Spatial filters,band-pass filters,brain-computer interfaces,classification algorithm,common spatial pattern algorithm,electroencephalogram,electroencephalography,feature extraction,filter bank common spatial pattern,medical signal processing,motor imagery-based brain computer interfaces,spatial filter},
pages = {2390--2397},
title = {{Filter Bank Common Spatial Pattern (FBCSP) in Brain-Computer Interface}},
year = {2008}
}
@inproceedings{Krizhevsky:2012:ICD:2999134.2999257,
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 dif-ferent classes. On the test data, we achieved top-1 and top-5 error rates of 37.5{\%} and 17.0{\%} which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully-connected layers with a final 1000-way softmax. To make train-ing faster, we used non-saturating neurons and a very efficient GPU implemen-tation of the convolution operation. To reduce overfitting in the fully-connected layers we employed a recently-developed regularization method called " dropout " that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3{\%}, compared to 26.2{\%} achieved by the second-best entry.},
address = {USA},
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
booktitle = {Proceedings of the 25th International Conference on Neural Information Processing Systems - Volume 1},
pages = {1097--1105},
publisher = {Curran Associates Inc.},
series = {NIPS'12},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
year = {2012}
}
@article{Schirrmeister2017,
abstract = {Deep learning with convolutional neural networks (deep ConvNets) has revolutionized computer vision through end-to-end learning, i.e. learning from the raw data. Now, there is increasing interest in using deep ConvNets for end-to-end EEG analysis. However, little is known about many important aspects of how to design and train ConvNets for end-to-end EEG decoding, and there is still a lack of techniques to visualize the informative EEG features the ConvNets learn. Here, we studied deep ConvNets with a range of different architectures, designed for decoding imagined or executed movements from raw EEG. Our results show that recent advances from the machine learning field, including batch normalization and exponential linear units, together with a cropped training strategy, boosted the deep ConvNets decoding performance, reaching or surpassing that of the widely-used filter bank common spatial patterns (FBCSP) decoding algorithm. While FBCSP is designed to use spectral power modulations, the features used by ConvNets are not fixed a priori. Our novel methods for visualizing the learned features demonstrated that ConvNets indeed learned to use spectral power modulations in the alpha, beta and high gamma frequencies. These methods also proved useful as a technique for spatially mapping the learned features, revealing the topography of the causal contributions of features in different frequency bands to decoding the movement classes. Our study thus shows how to design and train ConvNets to decode movement-related information from the raw EEG without handcrafted features and highlights the potential of deep ConvNets combined with advanced visualization techniques for EEG-based brain mapping.},
archivePrefix = {arXiv},
arxivId = {arXiv:1703.05051v1},
author = {Schirrmeister, Robin Tibor and Springenberg, Jost Tobias and Dominique, Lukas and Fiederer, Josef and Glasstetter, Martin and Eggensperger, Katharina and Tangermann, Michael and Hutter, Frank and Burgard, Wolfram and Ball, Tonio},
eprint = {arXiv:1703.05051v1},
journal = {arXiv},
keywords = {EEG analysis,Electroencephalography,brain mapping,brain-computer interface (BMI),brain-machine interface (BCI),end-to-end learning,machine learning,model interpretability},
title = {{Deep learning with convolutional neural networks for brain mapping and decoding of movement-related information from the human EEG Short title: Convolutional neural networks in EEG analysis}},
url = {https://arxiv.org/pdf/1703.05051.pdf},
year = {2017}
}
@article{Nguyen2012,
annote = {NULL},
author = {Nguyen, Phuoc and Tran, Dat and Huang, Xu and Sharma, Dharmendra},
isbn = {1601322178},
journal = {The International Conference on Artificial Intelligence},
keywords = {and fmri,and nirs are expensive,and nirs present long,brain computer interface,eeg,fmri,measure neural activity directly,meg,or bulky,person identification,relying instead on the,they do not,time constants in that},
title = {{A Proposed Feature Extraction Method for EEG-based Person Identification}},
year = {2012}
}
@article{Tompson2015,
abstract = {Abstract: Recent state-of-the-art performance on human-body pose estimation has been achieved with Deep Convolutional Networks (ConvNets). Traditional ConvNet architectures include pooling layers which reduce computational requirements, introduce invariance ...$\backslash$n},
archivePrefix = {arXiv},
arxivId = {1411.4280},
author = {Tompson, Jonathan and Goroshin, Ross and Jain, Arjun and LeCun, Y},
doi = {10.1109/CVPR.2015.7298664},
eprint = {1411.4280},
isbn = {9781467369640},
issn = {10636919},
journal = {arXiv.org},
keywords = {pose estimation},
pages = {1--9},
title = {{Efficient Object Localization Using Convolutional Networks}},
url = {https://arxiv.org/pdf/1411.4280.pdf},
year = {2015}
}
@article{He2015a,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Delving Deep into Rectifiers: Surpassing Human-Level Performance on
               ImageNet Classification},
  journal   = {CoRR},
  volume    = {abs/1502.01852},
  year      = {2015},
  url       = {http://arxiv.org/abs/1502.01852},
  archivePrefix = {arXiv},
  eprint    = {1502.01852},
  timestamp = {Wed, 07 Jun 2017 14:41:19 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HeZR015},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Bahdanaua,
abstract = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
archivePrefix = {arXiv},
arxivId = {1409.0473},
author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
doi = {10.1146/annurev.neuro.26.041002.131047},
eprint = {1409.0473},
isbn = {0147-006X (Print)},
issn = {0147-006X},
pmid = {14527267},
title = {{Neural Machine Translation by Jointly Learning to Align and Translate}},
url = {https://arxiv.org/pdf/1409.0473.pdf},
year = {2014}
}
@article{Moreno-Bote2014,
abstract = {Computational strategies used by the brain strongly depend on the amount of information that can be stored in population activity, which in turn strongly depends on the pattern of noise correlations. In vivo, noise correlations tend to be positive and proportional to the similarity in tuning properties. Such correlations are thought to limit information, which has led to the suggestion that decorrelation increases information. In contrast, we found, analytically and numerically, that decorrelation does not imply an increase in information. Instead, the only information-limiting correlations are what we refer to as differential correlations: correlations proportional to the product of the derivatives of the tuning curves. Unfortunately, differential correlations are likely to be very small and buried under correlations that do not limit information, making them particularly difficult to detect. We found, however, that the effect of differential correlations on information can be detected with relatively simple decoders.},
annote = {NULL},
author = {Moreno-Bote, Rub{\'{e}}n and Beck, Jeffrey and Kanitscheider, Ingmar and Pitkow, Xaq and Latham, Peter and Pouget, Alexandre},
doi = {10.1038/nn.3807},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {Brain research,Correlation method (Psychology),Memory storage (Psychology)},
month = {sep},
number = {10},
pages = {1410--1417},
publisher = {Nature Publishing Group},
title = {{Information-limiting correlations}},
volume = {17},
year = {2014}
}
@inproceedings{Moritz,
abstract = {Teaching machines to read natural language documents remains an elusive chal-lenge. Machine reading systems can be tested on their ability to answer questions posed on the contents of documents that they have seen, but until now large scale training and test datasets have been missing for this type of evaluation. In this work we define a new methodology that resolves this bottleneck and provides large scale supervised reading comprehension data. This allows us to develop a class of attention based deep neural networks that learn to read real documents and answer complex questions with minimal prior knowledge of language structure.},
archivePrefix = {arXiv},
arxivId = {1506.03340},
author = {Hermann, KM and Kocisky, T and Grefenstette, E},
booktitle = {NIPS},
eprint = {1506.03340},
issn = {10495258},
pages = {1--9},
title = {{Teaching machines to read and comprehend}},
url = {http://papers.nips.cc/paper/5945-teaching-machines-to-read-and-comprehend.pdf},
year = {2015}
}
@article{Bergstra2013,
abstract = {—Sequential model-based optimization (also known as Bayesian op-timization) is one of the most efficient methods (per function evaluation) of function minimization. This efficiency makes it appropriate for optimizing the hyperparameters of machine learning algorithms that are slow to train. The Hyperopt library provides algorithms and parallelization infrastructure for per-forming hyperparameter optimization (model selection) in Python. This paper presents an introductory tutorial on the usage of the Hyperopt library, including the description of search spaces, minimization (in serial and parallel), and the analysis of the results collected in the course of minimization. The paper closes with some discussion of ongoing and future work.},
author = {Bergstra, James and Yamins, Dan and Cox, David D},
journal = {Proc. of the 12th Python in Science Conf.},
keywords = {Index Terms—Bayesian optimization,hyperparameter optimization,model se-lection},
pages = {13--20},
title = {{Hyperopt: A Python Library for Optimizing the Hyperparameters of Machine Learning Algorithms}},
year = {2013}
}
@incollection{Herff2017,
abstract = {For the last two decades, brain-computer interface (BCI) research has worked towards practical and useful applications for communication and control. Yet, many BCI communication approaches suffer from unnatural interaction or time-consuming user training. As continuous speech provides a very natural communica-tion approach, it has been a long standing question whether it is possible to develop BCIs that perform speech recognition from cortical activity. Imagined speech as a BCI paradigm for locked-in patients would mean a large improvement in communi-cation speed and usability without the need for cumbersome spelling using individual letters. We showed for the first time that automatic speech recognition from neural signals is possible. Here, we evaluate the feasibility of speech recognition from neural signals using only temporal offsets associated with speech production and omitting information from speech perception. This analysis provides first insights into the potential usage of imagined speech processes for speech recognition, for which no perceptive activity is present.},
author = {Herff, Christian and de Pesters, Adriana and Heger, Dominic and Brunner, Peter and Schalk, Gerwin and Schultz, Tanja},
booktitle = {Brain-Computer Interface Research: A State-of-the-Art Summary},
doi = {10.1007/978-3-319-57132-4_3},
keywords = {Automatic speech recognition ⋅ ASR ⋅,Brain-computer interface,Speech ⋅ BCI ⋅},
pages = {21--29},
title = {{Towards Continuous Speech Recognition for BCI}},
year = {2017}
}
@inproceedings{Zhao2015a,
abstract = {This paper presents a new dataset combining 3 modalities (EEG, facial, and audio) during imagined and vocalized phonemic and single-word prompts. We pre-process the EEG data, compute features for all 3 modalities, and perform binary classification of phonological categories using a combination of these modalities. For example, a deep-belief network obtains accuracies over 90{\%} on identifying consonants, which is significantly more accurate than two baseline support vector machines. We also classify between the different states (resting, stimuli, active thinking) of the recording, achieving accuracies of 95{\%}. These data may be used to learn multimodal relationships, and to develop silent-speech and brain-computer interfaces.},
author = {Zhao, Shunan and Rudzicz, Frank},
booktitle = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
doi = {10.1109/ICASSP.2015.7178118},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao, Rudzicz - Unknown - CLASSIFYING PHONOLOGICAL CATEGORIES IN IMAGINED AND ARTICULATED SPEECH.pdf:pdf},
isbn = {9781467369978},
issn = {15206149},
keywords = {Phonological categories,deep-belief networks,electroencephalography,speech articulation},
pages = {992--996},
title = {{Classifying phonological categories in imagined and articulated speech}},
volume = {2015-Augus},
year = {2015}
}
@incollection{NIPS2017_6698,
abstract = {Deep Learning has revolutionized vision via convolutional neural networks (CNNs) and natural language processing via recurrent neural networks (RNNs). However, success stories of Deep Learning with standard feed-forward neural networks (FNNs) are rare. FNNs that perform well are typically shallow and, therefore cannot exploit many levels of abstract representations. We introduce self-normalizing neural networks (SNNs) to enable high-level abstract representations. While batch normalization requires explicit normalization, neuron activations of SNNs automatically converge towards zero mean and unit variance. The activation function of SNNs are "scaled exponential linear units" (SELUs), which induce self-normalizing properties. Using the Banach fixed-point theorem, we prove that activations close to zero mean and unit variance that are propagated through many network layers will converge towards zero mean and unit variance -- even under the presence of noise and perturbations. This convergence property of SNNs allows to (1) train deep networks with many layers, (2) employ strong regularization, and (3) to make learning highly robust. Furthermore, for activations not close to unit variance, we prove an upper and lower bound on the variance, thus, vanishing and exploding gradients are impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning repository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with standard FNNs and other machine learning methods such as random forests and support vector machines. SNNs significantly outperformed all competing FNN methods at 121 UCI tasks, outperformed all competing methods at the Tox21 dataset, and set a new record at an astronomy data set. The winning SNN architectures are often very deep. Implementations are available at: github.com/bioinf-jku/SNNs.},
archivePrefix = {arXiv},
arxivId = {1706.02515},
author = {Klambauer, G{\"{u}}nter and Unterthiner, Thomas and Mayr, Andreas and Hochreiter, Sepp},
booktitle = {Advances in Neural Information Processing Systems 30},
doi = {1706.02515},
editor = {Guyon, I and Luxburg, U V and Bengio, S and Wallach, H and Fergus, R and Vishwanathan, S and Garnett, R},
eprint = {1706.02515},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Klambauer et al. - Unknown - Self-Normalizing Neural Networks.pdf:pdf},
pages = {972--981},
publisher = {Curran Associates, Inc.},
title = {{Self-Normalizing Neural Networks}},
url = {http://arxiv.org/abs/1706.02515},
year = {2017}
}
@article{Brown2009,
abstract = {A sizable literature on the neuroimaging of speech production has reliably shown activations in the oro-facial region of the primary motor cortex. These activations have invariably been interpreted as reflecting ''mouth " functioning and thus articulation. We used functional magnetic resonance imaging to compare an overt speech task with tongue movement, lip movement, and vowel phonation. The results showed that the strongest motor activation for speech was the somatotopic larynx area of the motor cortex, thus reflecting the significant contribution of phonation to speech production. In order to analyze further the phonatory component of speech, we performed a voxel-based meta-analysis of neuroimaging studies of syllable-singing (11 studies) and compared the results with a previously-published meta-analysis of oral reading (11 studies), showing again a strong overlap in the larynx motor area. Overall, these findings highlight the under-recognized presence of phonation in imaging studies of speech production, and sup-port the role of the larynx motor cortex in mediating the ''melodicity " of speech.},
author = {Brown, Steven and Laird, Angela R and Pfordresher, Peter Q and Thelen, Sarah M and Turkeltaub, Peter and Liotti, Mario},
doi = {10.1016/j.bandc.2008.12.006},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brown et al. - 2009 - The somatotopy of speech Phonation and articulation in the human motor cortex.pdf:pdf},
issn = {02782626},
journal = {Brain and Cognition},
keywords = {ALE,Articulation,Brain,Larynx,Meta-analysis,Neuroimaging,Phonation,Speech,Vocalization,fMRI},
month = {jun},
number = {1},
pages = {31--41},
title = {{The somatotopy of speech: Phonation and articulation in the human motor cortex}},
volume = {70},
year = {2009}
}
@inproceedings{Bashivan2016,
abstract = {One of the challenges in modeling cognitive events from electroencephalogram (EEG) data is finding representations that are invariant to inter-and intra-subject differences, as well as to inherent noise associated with EEG data collection. Herein, we propose a novel approach for learning such representations from multi-channel EEG time-series, and demonstrate its advantages in the context of mental load classification task. First, we transform EEG activities into a sequence of topology-preserving multi-spectral images, as opposed to standard EEG analysis techniques that ignore such spatial information. Next, we train a deep recurrent-convolutional network inspired by state-of-the-art video classification techniques to learn robust representations from the sequence of images. The proposed ap-proach is designed to preserve the spatial, spectral, and temporal structure of EEG which leads to finding features that are less sensitive to variations and distortions within each dimension. Empirical evaluation on the cognitive load classification task demonstrated significant improvements in classification accuracy over current state-of-the-art approaches in this field.},
archivePrefix = {arXiv},
arxivId = {arXiv:1511.06448v3},
author = {Bashivan, Pouya and Rish, Irina and Yeasin, Mohammed and Codella, Noel},
booktitle = {ICLR 2016},
eprint = {arXiv:1511.06448v3},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bashivan et al. - Unknown - LEARNING REPRESENTATIONS FROM EEG WITH DEEP RECURRENT-CONVOLUTIONAL NEURAL NETWORKS.pdf:pdf},
isbn = {9783901608353},
pages = {1--15},
title = {{Learning Representations From Eeg With Deep Recurrent-Convolutional Neural Networks}},
url = {https://arxiv.org/pdf/1511.06448.pdf},
year = {2016}
}
@article{Oldfield1971,
author = {Oldfield, R.C.},
doi = {10.1016/0028-3932(71)90067-4},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - The Assessment and Analysis of Handedness The Edinburgh Inventory.pdf:pdf},
issn = {00283932},
journal = {Neuropsychologia},
month = {mar},
number = {1},
pages = {97--113},
title = {{The assessment and analysis of handedness: The Edinburgh inventory}},
volume = {9},
year = {1971}
}
@article{Benavoli,
abstract = {The machine learning community adopted the use of null hypothesis significance testing (NHST) in order to ensure the statistical validity of results. Many scientific fields however realized the shortcomings of frequentist reasoning and in the most radical cases even banned its use in publications. We should do the same: just as we have embraced the Bayesian paradigm in the development of new machine learning methods, so we should also use it in the analysis of our own results. We argue for abandonment of NHST by exposing its fallacies and, more importantly, offer better - more sound and useful - alternatives for it.},
archivePrefix = {arXiv},
arxivId = {1606.04316},
author = {Benavoli, Alessio and Corani, Giorgio and Demsar, Janez and Zaffalon, Marco},
eprint = {1606.04316},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Benavoli et al. - Unknown - Time for a Change a Tutorial for Comparing Multiple Classifiers Through Bayesian Analysis.pdf:pdf},
issn = {15337928},
keywords = {Bayesian correlated t-test,Bayesian hierarchical correlated t-test,Bayesian hypothesis tests,Bayesian signed-rank test,comparing classifiers,null hypothesis significance testing,pitfalls of p-values},
title = {{Time for a change: a tutorial for comparing multiple classifiers through Bayesian analysis}},
url = {http://arxiv.org/abs/1606.04316},
year = {2016}
}
@article{Trott2017,
author = {{Rezazadeh Sereshkeh}, Alborz and Trott, Robert and Bricout, Aurelien and Chau, Tom},
doi = {10.1109/TASLP.2017.2758164},
file = {:home/demetres/Downloads/EEG Classification of Covert Speech Using Regularized Neural Networks.pdf:pdf},
issn = {2329-9290},
journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
month = {dec},
number = {12},
pages = {2292--2300},
title = {{EEG Classification of Covert Speech Using Regularized Neural Networks}},
volume = {25},
year = {2017}
}
@article{Bell1995,
abstract = {We d e r i v e a new self-organising learning algorithm which maximises the information transferred in a network of non-linear units. The algo-rithm does not assume any knowledge of the input distributions, and is deened here for the zero-noise limit. Under these conditions, infor-mation maximisation has extra properties not found in the linear case (Linsker 1989). The non-linearities in the transfer function are able to pick up higher-order moments of the input distributions and perform something akin to true redundancy reduction between units in the out-put representation. This enables the network to separate statistically independent components in the inputs: a higher-order generalisation of Principal Components Analysis. We apply the network to the source separation (or cocktail party) problem, successfully separating unknown mixtures of up to ten speak-ers. We also show t h a t a v ariant on the network architecture is able to perform blind deconvolution (cancellation of unknown echoes and reverberation in a speech signal). Finally, w e d e r i v e dependencies of information transfer on time delays. We suggest that information max-imisation provides a unifying framework for problems iblind' signal processing. Please send comments to tony@salk.edu. This paper will appear as Neural Computation, 7, 6, 1004-1034 (1995). The reference for this version is:},
author = {Bell, Anthony J and Sejnowski, Terrence J},
doi = {10.1162/neco.1995.7.6.1129},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bell, Sejnowski - 1995 - An information-maximisation approach t o blind separation and blind deconvolution.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
month = {nov},
number = {6},
pages = {1129--1159},
title = {{An Information-Maximization Approach to Blind Separation and Blind Deconvolution}},
volume = {7},
year = {1995}
}
@article{VanDenOord,
abstract = {This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.},
archivePrefix = {arXiv},
arxivId = {1609.03499},
author = {van den Oord, Aaron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
doi = {10.1109/ICASSP.2009.4960364},
eprint = {1609.03499},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Van Den Oord et al. - Unknown - WAVENET A GENERATIVE MODEL FOR RAW AUDIO.pdf:pdf},
isbn = {9783901882760},
issn = {0899-7667},
pmid = {18785855},
title = {{WaveNet: A Generative Model for Raw Audio}},
url = {https://arxiv.org/pdf/1609.03499v2.pdf},
year = {2016}
}
@article{LeCun2015,
abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
archivePrefix = {arXiv},
arxivId = {arXiv:1312.6184v5},
author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey and Y., Lecun and Y., Bengio and G., Hinton},
doi = {10.1038/nature14539},
eprint = {arXiv:1312.6184v5},
file = {:home/demetres/Documents/Papers/Computers/ML/NatureDeepReview.pdf:pdf},
isbn = {3135786504},
issn = {0028-0836},
journal = {Nature},
number = {7553},
pages = {436--444},
pmid = {26017442},
title = {{Deep learning}},
volume = {521},
year = {2015}
}
@article{Raffel2015,
abstract = {We propose a simplified model of attention which is applicable to feed-forward neural networks and demonstrate that the resulting model can solve the synthetic "addition" and "multiplication" long-term memory problems for sequence lengths which are both longer and more widely varying than the best published results for these tasks.},
archivePrefix = {arXiv},
arxivId = {1512.08756},
author = {Raffel, Colin and Ellis, Daniel P W},
eprint = {1512.08756},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Raffel, Ellis - Unknown - Workshop track -ICLR 2016 FEED-FORWARD NETWORKS WITH ATTENTION CAN SOLVE SOME LONG-TERM MEMORY PROBLEMS.pdf:pdf},
title = {{Feed-Forward Networks with Attention Can Solve Some Long-Term Memory Problems}},
url = {https://arxiv.org/pdf/1512.08756.pdf},
year = {2015}
}
@article{Sutskever2014,
abstract = {Deep Neural Networks (DNNs) are powerful models that have achieved excel-lent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Fi-nally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem easier.},
archivePrefix = {arXiv},
arxivId = {1409.3215},
author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V},
doi = {10.1007/s10107-014-0839-0},
eprint = {1409.3215},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Sutskever, Vinyals, Le - Unknown - Sequence to Sequence Learning with Neural Networks.pdf:pdf},
isbn = {1409.3215},
issn = {09205691},
journal = {Advances in Neural Information Processing Systems (NIPS)},
pages = {3104--3112},
pmid = {2079951},
title = {{Sequence to sequence learning with neural networks}},
year = {2014}
}
@article{Kadis2011,
abstract = {To characterize the developmental trajectory for expressive language representation and to test competing explanations for the relative neuroplasticity of language in childhood, we studied 28 healthy children and adolescents (aged 5–19 years) participating in a covert verb generation task in magnetoencephalography. Lateralization of neuromagnetic responses in the frontal lobe was quantified using a bootstrap statistical thresholding procedure for differential beamformer analyses. We observed a significant positive correlation between left hemisphere lateralization and age. Findings suggest that adult-typical left hemisphere lateralization emerges from an early bilateral language network, which may explain the pediatric advantage for interhemispheric plasticity of language. (JINS, 2011, 17, 896–904)},
author = {Kadis, Darren S and Pang, Elizabeth W and Mills, Travis and Taylor, Margot J and McAndrews, Mary Pat and Smith, Mary Lou},
doi = {10.1017/S1355617711000932},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kadis et al. - 2011 - Characterizing the Normal Developmental Trajectory of Expressive Language Lateralization Using Magnetoencephalogra.pdf:pdf},
issn = {1355-6177},
journal = {Journal of the International Neuropsychological Society},
keywords = {Beamformer,Broca area,Child,Neuronal plasticity,Synthetic aperture magnetometry},
month = {sep},
number = {05},
pages = {896--904},
title = {{Characterizing the Normal Developmental Trajectory of Expressive Language Lateralization Using Magnetoencephalography}},
volume = {17},
year = {2011}
}
@inproceedings{Krell2017,
abstract = {For deep learning on image data, a$\backslash$ncommon approach is to augment the training data by artificial$\backslash$nnew images, using techniques like moving windows, scaling,$\backslash$naffine distortions, and elastic deformations. In contrast to image$\backslash$ndata, electroencephalographic (EEG) data suffers even more$\backslash$nfrom the lack of sufficient training data. Methods: We suggest$\backslash$nand evaluate rotational distortions similar to affine/rotational$\backslash$ndistortions of images to generate augmented data. Results: Our$\backslash$napproach increases the performance of signal processing chains$\backslash$nfor EEG-based brain-computer interfaces when rotating only$\backslash$naround y- and z-axis with an angle around 18 degrees to$\backslash$ngenerate new data. Conclusion: This shows that our processing$\backslash$nefficient approach generates meaningful data and encourages$\backslash$nto look for further new methods for EEG data augmentation.},
author = {Krell, Mario Michael and Kim, Su-Kyoung},
booktitle = {Proceedings of the 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society. The 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (IEEE EMBC), July 11-15, JeJu Island, South K},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krell, Kim - Unknown - Rotational Data Augmentation for Electroencephalographic Data.pdf:pdf},
number = {Section II},
pages = {n.a.},
title = {{Rotational Data Augmentation for Electroencephalographic Data}},
year = {2017}
}
@article{Guger2000,
abstract = {—Electroencephalogram (EEG) recordings during right and left motor imagery allow one to establish a new com-munication channel for, e.g., patients with amyotrophic lateral sclerosis. Such an EEG-based brain–computer interface (BCI) can be used to develop a simple binary response for the control of a device. Three subjects participated in a series of on-line sessions to test if it is possible to use common spatial patterns to analyze EEG in real time in order to give feedback to the subjects. Furthermore, the classification accuracy that can be achieved after only three days of training was investigated. The patterns are estimated from a set of multichannel EEG data by the method of common spatial patterns and reflect the specific activation of cortical areas. By construction, common spatial patterns weight each electrode according to its importance to the discrimination task and suppress noise in individual channels by using corre-lations between neighboring electrodes. Experiments with three subjects resulted in an error rate of 2, 6 and 14{\%} during on-line discrimination of left-and right-hand motor imagery after three days of training and make common spatial patterns a promising method for an EEG-based brain–computer interface. Index Terms—Brain–computer interface (BCI), common spatial patterns (CSP), event-related desynchronization (ERD), real-time software.},
author = {Guger, C and Ramoser, H and Pfurtscheller, G},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Guger, Ramoser, Pfurtscheller - 2000 - Real-Time EEG Analysis with Subject-Specific Spatial Patterns for a Brain–Computer Interface (B.pdf:pdf},
journal = {IEEE TRANSACTIONS ON REHABILITATION ENGINEERING},
number = {4},
pages = {447--456},
title = {{Real-Time EEG Analysis with Subject-Specific Spatial Patterns for a Brain – Computer Interface (BCI)}},
volume = {8},
year = {2000}
}
@article{Bahdanaub,
abstract = {Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.},
archivePrefix = {arXiv},
arxivId = {1409.0473},
author = {Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
doi = {10.1146/annurev.neuro.26.041002.131047},
eprint = {1409.0473},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bahdanau, Cho, Bengio - Unknown - NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE(3).pdf:pdf},
isbn = {0147-006X (Print)},
issn = {0147-006X},
pmid = {14527267},
title = {{Neural Machine Translation by Jointly Learning to Align and Translate}},
url = {https://arxiv.org/pdf/1409.0473.pdf},
year = {2014}
}
@article{Poulos2001,
abstract = {Person identification based on spectral information extracted from the EEG is addressed in this work a problem that has not yet been seen in a signal processing framework. Spectral features are extracted non-parametrically from real EEG data recorded from healthy individuals. Neural network classification is applied on these features using a Learning Vector Quantizer in an attempt to experimentally investigate the connection between a person's EEG and genetically specific information. The proposed method, compared with previously proposed methods, has yielded encouraging correct classification scores in the range of 80{\%} to 100{\%} (case-dependent). These results are in agreement with previous research showing evidence that the EEG carries genetic information},
annote = {NULL},
author = {Poulos, M and Rangoussi, M and Alexandris, N and Evangelou, A},
doi = {10.1080/14639230118937},
file = {:home/demetres/Downloads/On the use of EEG features towards person identification via neural networks.pdf:pdf},
isbn = {1463923001001},
issn = {1753-8157},
journal = {Med Inform.Internet.Med},
keywords = {Adult,Alpha Rhythm,Anthropology,Physical,Beta Rhythm,Classification,Electroencephalography,False Negative Reactions,False Positive Reactions,Female,Fourier Analysis,Human,Learning,Male,Medical Informatics Applications,Medical Informatics Computing,Middle Aged,Neural Networks (Computer),Patient Identification Systems,Pedigree,Sensitivity and Specificity,Signal Processing,Computer-Assisted,Support,Non-U.S.Gov't,Theta Rhythm,methods,neural},
number = {1},
pages = {35--48},
title = {{On the use of EEG features towards person identification via neural networks}},
volume = {26},
year = {2001}
}
@article{Ghosh2008a,
abstract = {PurposeThis study investigated the network of brain regions involved in overt production of vowels, monosyllables, and bisyllables to test hypotheses derived from the Directions Into Velocities of Articulators (DIVA) model of speech production (Guenther, Ghosh, {\&} Tourville, 2006). The DIVA model predicts left lateralized activity in inferior frontal cortex when producing a single syllable or phoneme and increased cerebellar activity for consonant–vowel syllables compared with steady-state vowels. MethodSparse sampling functional magnetic resonance imaging (fMRI) was used to collect data from 10 right-handed speakers of American English while producing isolated monosyllables (e.g., “ba,” “oo”). Data were analyzed using both voxel-based and participant-specific anatomical region-of-interest–based techniques. ResultsOvert production of single monosyllables activated a network of brain regions, including left ventral premotor cortex, left posterior inferior frontal gyrus, bilateral supplementary motor area, sensorimotor cortex, auditory cortex, thalamus, and cerebellum. Paravermal cerebellum showed greater activity for consonant-vowel syllables compared to vowels. ConclusionsThe finding of left-lateralized premotor cortex activity supports the DIVA model prediction that this area contains cell populations representing syllable motor programs without regard for semantic content. Furthermore, the superior paravermal cerebellum is more active for consonant–vowel syllables compared with vowels, perhaps due to increased timing constraints for consonant production.},
author = {Ghosh, Satrajit S and Tourville, Jason A and Guenther, Frank H},
doi = {10.1044/1092-4388(2008/07-0119)},
file = {:home/demetres/Downloads/Ghosh{\_}et{\_}al-2008-Journal{\_}of{\_}Speech,{\_}Language,{\_}and{\_}Hearing{\_}Research.pdf:pdf},
issn = {1092-4388},
journal = {Journal of Speech, Language, and Hearing Research},
keywords = {broca,cerebellum,hemispheric asymmetry,region-of-interest analysis,s area,sparse clustered imaging,speech motor control},
number = {5},
pages = {1183--1202},
title = {{A Neuroimaging Study of Premotor Lateralization and Cerebellar Involvement in the Production of Phonemes and Syllables}},
volume = {51},
year = {2008}
}
@article{Tabar2017,
abstract = {-Adaptation of motor imagery EEG classification model based on tensor decomposition Xinyang Li, Cuntai Guan, Haihong Zhang et al. -Multiresolution analysis over simple graphs for brain computer interfaces J Asensio-Cubero, J Q Gan and R Palaniappan -Recent citations Deep learning with convolutional neural networks for EEG decoding and visualization Robin Tibor Schirrmeister et al -Virtual and Actual Humanoid Robot Control with Four-Class Motor-Imagery-Based Optical Brain-Computer Interface Alyssa M. Batula et al -This content was downloaded from IP address 142.150.190.39 on 15/09/2017 at 16:03},
author = {Tabar, Yousef Rezaei and Halici, Ugur},
doi = {10.1088/1741-2560/14/1/016003},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Thomas, Guan, Lau - Unknown - Adaptive tracking of discriminative frequency components in electroencephalograms for a robust BCI.pdf:pdf},
issn = {1741-2560},
journal = {Journal of Neural Engineering},
month = {feb},
number = {1},
pages = {016003},
title = {{A novel deep learning approach for classification of EEG motor imagery signals}},
volume = {14},
year = {2017}
}
@article{Blankertz2007,
abstract = {Brain-Computer Interface (BCI) systems establish a direct communication channel from the brain to an output device. These systems use brain signals recorded from the scalp, the surface of the cortex, or from inside the brain to enable users to control a variety of applications. BCI systems that bypass conventional motor output pathways of nerves and muscles can provide novel control options for paralyzed patients. One classical approach to establish EEG-based control is to set up a system that is controlled by a specific EEG feature which is known to be susceptible to conditioning and to let the subjects learn the voluntary control of that feature. In contrast, the Berlin Brain-Computer Interface (BBCI) uses well established motor competencies of its users and a machine learning approach to extract subject-specific patterns from high-dimensional features optimized for detecting the user's intent. Thus the long subject training is replaced by a short calibration measurement (20 min) and machine learning (1 min). We report results from a study in which 10 subjects, who had no or little experience with BCI feedback, controlled computer applications by voluntary imagination of limb movements: these intentions led to modulations of spontaneous brain activity specifically, somatotopically matched sensorimotor 7-30 Hz rhythms were diminished over pericentral cortices. The peak information transfer rate was above 35 bits per minute (bpm) for 3 subjects, above 23 bpm for two, and above 12 bpm for 3 subjects, while one subject could achieve no BCI control. Compared to other BCI systems which need longer subject training to achieve comparable results, we propose that the key to quick efficiency in the BBCI system is its flexibility due to complex but physiologically meaningful features and its adaptivity which respects the enormous inter-subject variability. {\textcopyright} 2007 Elsevier Inc. All rights reserved.},
author = {Blankertz, Benjamin and Dornhege, Guido and Krauledat, Matthias and M{\"{u}}ller, Klaus- Robert and Curio, Gabriel},
doi = {10.1016/j.neuroimage.2007.01.051},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blankertz et al. - 2007 - The non-invasive Berlin Brain–Computer Interface Fast acquisition of effective performance in untrained s(2).pdf:pdf},
isbn = {1053-8119},
issn = {10538119},
journal = {NeuroImage},
number = {2},
pages = {539--550},
pmid = {17475513},
title = {{The non-invasive Berlin Brain-Computer Interface: Fast acquisition of effective performance in untrained subjects}},
volume = {37},
year = {2007}
}
@article{Muller-Gerking1999,
abstract = {We devised spatial filters for multi-channel EEG that lead to signals which discriminate optimally between two conditions. We demonstrate the effectiveness of this method by classifying single-trial EEGs, recorded during preparation for movements of the left or fight index finger or the fight foot. The classification rates for 3 subjects were 94, 90 and 84{\%}, respectively. The filters are estimated from a set of multi-channel EEG data by the method of Common Spatial Patterns, and reflect the selective activation of cortical areas. By construction, we obtain an automatic weighing of electrodes according to their importance for the classification task. Computationally, this method is parallel by nature, and demands only the evaluation of scalar products. Therefore, it is well suited for on-line data processing. The recognition rates obtained with this relatively simple method are as good as, or higher than those obtained previously with other methods. The high recognition rates and the method's procedural and computational simplicity make it a particularly promising method for an EEG- based brain-computer interface.},
author = {M{\"{u}}ller-Gerking, Johannes and Pfurtscheller, Gert and Flyvbjerg, Henrik},
doi = {10.1016/S1388-2457(98)00038-8},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/{\`{E}}ller-Gerking, Pfurtscheller, Flyvbjerg - Unknown - Designing optimal spatial {\textregistered}lters for single-trial EEG classi{\textregistered}cation in a movement.pdf:pdf},
isbn = {1388-2457},
issn = {13882457},
journal = {Clinical Neurophysiology},
keywords = {EEG classification,Event-related desynchronization,Human,Mu rhythm,Sensorimotor cortex,Voluntary movement},
number = {5},
pages = {787--798},
pmid = {10400191},
title = {{Designing optimal spatial filters for single-trial EEG classification in a movement task}},
volume = {110},
year = {1999}
}
@article{Lawhern2017,
  author    = {Vernon J. Lawhern and
               Amelia J. Solon and
               Nicholas R. Waytowich and
               Stephen M. Gordon and
               Chou P. Hung and
               Brent J. Lance},
  title     = {EEGNet: {A} Compact Convolutional Network for EEG-based Brain-Computer
               Interfaces},
  journal   = {CoRR},
  volume    = {abs/1611.08024},
  year      = {2016},
  url       = {http://arxiv.org/abs/1611.08024},
  archivePrefix = {arXiv},
  eprint    = {1611.08024},
  timestamp = {Wed, 07 Jun 2017 14:41:19 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/LawhernSWGHL16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Cichy2016,
abstract = {The complex multi-stage architecture of cortical visual pathways provides the neural basis for efficient visual object recognition in humans. However, the stage-wise computations therein remain poorly understood. Here, we compared temporal (magnetoencephalography) and spatial (functional MRI) visual brain representations with representations in an artificial deep neural network (DNN) tuned to the statistics of real-world visual recognition. We showed that the DNN captured the stages of human visual processing in both time and space from early visual areas towards the dorsal and ventral streams. Further investigation of crucial DNN parameters revealed that while model architecture was important, training on real-world categorization was necessary to enforce spatio-temporal hierarchical relationships with the brain. Together our results provide an algorithmically informed view on the spatio-temporal dynamics of visual object recognition in the human visual brain. Visual object recognition in humans is mediated by complex multi-stage processing of visual information emerg-ing rapidly in a distributed network of cortical regions 1–7 . Understanding visual object recognition in cortex thus requires a quantitative model that captures the complexity of the underlying spatio-temporal dynamics 8–10 . A major impediment in creating such a model is the highly nonlinear and sparse nature of neural tuning properties in mid-and high-level visual areas 11–13 that is difficult to capture experimentally, and thus unknown. Previous approaches to modeling object recognition in cortex relied on extrapolation of principles from well understood lower visual areas such as V1 8,9 and strong manual intervention, achieving only modest task perfor-mance compared to humans. Here we take an alternative route, constructing and comparing against brain signals a visual computational model based on deep neural networks (DNNs) 14–16 , i.e. computer vision models in which model neuron tuning properties are set by supervised learning without manual intervention 14,17 . DNNs are the best performing models on computer vision object recognition benchmarks and yield human performance levels on object categoriza-tion 18,19 . We used a tripartite strategy to reveal the spatio-temporal processing cascade underlying human visual object recognition by DNN model comparisons. First, as object recognition is a process rapidly unfolding over time 3,20–22 , we compared DNN visual representa-tions to millisecond resolved magnetoencephalography (MEG) brain data. Our results delineate an ordered relationship between the stages of processing in a DNN and the time course with which object representations emerge in the human brain 23 . Second, as object recognition recruits a multitude of distributed brain regions, a full account of object recogni-tion needs to go beyond the analysis of a few pre-defined brain regions 24–28 , determining the relationship between DNNs and the whole brain. Using a spatially unbiased approach, we revealed a hierarchical relationship between DNNs and the processing cascade of both the ventral and dorsal visual pathway.},
author = {Cichy, Radoslaw Martin and Khosla, Aditya and Pantazis, Dimitrios and Torralba, Antonio and Oliva, Aude},
doi = {10.1038/srep27755},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cichy et al. - 2016 - Comparison of deep neural networks to spatio-temporal cortical dynamics of human visual object recognition reveals.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
month = {sep},
number = {1},
pages = {27755},
title = {{Comparison of deep neural networks to spatio-temporal cortical dynamics of human visual object recognition reveals hierarchical correspondence}},
volume = {6},
year = {2016}
}
@article{Yu2014,
author = {Yu, Vickie Y and MacDonald, Matt J. and Oh, Anna and Hua, Gordon N and {De Nil}, Luc F. and Pang, Elizabeth W},
doi = {10.1037/a0037470},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu et al. - 2014 - Developmental Psychology Age-Related Sex Differences in Language Lateralization A Magnetoencephalography Study in Ch.pdf:pdf},
issn = {1939-0599},
journal = {Developmental Psychology},
keywords = {adult,dominance is lateralized to,event-related desynchroni-,gamma oscillations,in a typical right-handed,inferior frontal gyrus,it is well accepted,magnetoencephalography,that language,the brain and that,the left hemisphere of,verb generation,zation},
number = {9},
pages = {2276--2284},
title = {{Age-related sex differences in language lateralization: A magnetoencephalography study in children.}},
volume = {50},
year = {2014}
}
@article{Ye2017,
abstract = {Video Question Answering is a challenging problem in visual information retrieval, which provides the answer to the referenced video content according to the question. However, the existing visual question answering approaches mainly tackle the problem of static image question, which may be ineffectively for video question answering due to the insufficiency of modeling the temporal dynamics of video contents. In this paper, we study the problem of video question answering by modeling its temporal dynamics with frame-level attention mechanism. We propose the attribute-augmented attention network learning framework that enables the joint frame-level attribute detection and unified video representation learning for video question answering. We then incorporate the multi-step reasoning process for our proposed attention network to further improve the performance. We construct a large-scale video question answering dataset. We conduct the experiments on both multiple-choice and open-ended video question answering tasks to show the effectiveness of the proposed method.},
archivePrefix = {arXiv},
arxivId = {1707.06355},
author = {Ye, Yunan and Zhao, Zhou and Li, Yimeng and Chen, Long and Xiao, Jun and Zhuang, Yueting},
doi = {10.1145/3077136.3080655},
eprint = {1707.06355},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao et al. - 2017 - Video Question Answering via Hierarchical Spatio-Temporal Attention Networks.pdf:pdf},
isbn = {9781450350228},
keywords = {Machine Learning: Data Mining,Machine Learning: Neural Networks,Natural Language Processing: Information Retrieval},
title = {{Video Question Answering via Attribute-Augmented Attention Network Learning}},
url = {http://arxiv.org/abs/1707.06355},
year = {2017}
}
@article{Yu2015,
abstract = {Voice onset time (VOT) is a temporal acoustic parameter that reflects motor speech coordination skills. This study investigated the patterns of age and sex differences across development of voice onset time in a group of 70 English-speaking children, ranging in age from 4.1 to 18.4 years, and 12 young adults. The effect of the number of syllables on VOT patterns was also examined. Speech samples were elicited by producing syllables /pa/ and /pataka/. Results supported previous findings showing that younger children produce longer VOT values with higher levels of variability. Markedly higher VOT values and increased variability were found for boys at ages between 8 and 11 years, confirming sex differences in VOT patterns and patterns of variability. In addition, all participants consistently produced shorter VOT with higher variability for multisyllables than monosyllables, indicating an effect of syllable number. Possible explanations for these findings and clinical implications are discussed.},
annote = {NULL},
author = {Yu, Vickie. Y. and {De Nil}, L. F. and Pang, E. W.},
doi = {10.1177/0023830914522994},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu, De Nil, Pang - 2015 - Effects of Age, Sex and Syllable Number on Voice Onset Time Evidence from Children's Voiceless Aspirated Stops.pdf:pdf},
issn = {0023-8309},
journal = {Language and Speech},
keywords = {Voice onset time,sex differences,syllable number,variability patterns},
number = {2},
pages = {152--167},
title = {{Effects of Age, Sex and Syllable Number on Voice Onset Time: Evidence from Children's Voiceless Aspirated Stops}},
volume = {58},
year = {2015}
}
@article{Zeiler2013,
abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. We also perform an ablation study to discover the performance contribution from different model layers. This enables us to find model architectures that outperform Krizhevsky $\backslash$etal on the ImageNet classification benchmark. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
archivePrefix = {arXiv},
arxivId = {1311.2901},
author = {Zeiler, Matthew D and Fergus, Rob},
doi = {10.1007/978-3-319-10590-1_53},
eprint = {1311.2901},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zeiler, Fergus - Unknown - Visualizing and Understanding Convolutional Networks.pdf:pdf},
isbn = {978-3-319-10589-5},
issn = {978-3-319-10589-5},
month = {nov},
pages = {1--11},
pmid = {26353135},
title = {{Visualizing and Understanding Convolutional Networks}},
url = {https://arxiv.org/pdf/1311.2901.pdf},
year = {2013}
}
@article{Schuster1997,
abstract = {In the first part of this paper, a regular recurrent neural$\backslash$nnetwork (RNN) is extended to a bidirectional recurrent neural network$\backslash$n(BRNN). The BRNN can be trained without the limitation of using input$\backslash$ninformation just up to a preset future frame. This is accomplished by$\backslash$ntraining it simultaneously in positive and negative time direction.$\backslash$nStructure and training procedure of the proposed network are explained.$\backslash$nIn regression and classification experiments on artificial data, the$\backslash$nproposed structure gives better results than other approaches. For real$\backslash$ndata, classification experiments for phonemes from the TIMIT database$\backslash$nshow the same tendency. In the second part of this paper, it is shown$\backslash$nhow the proposed bidirectional structure can be easily modified to allow$\backslash$nefficient estimation of the conditional posterior probability of$\backslash$ncomplete symbol sequences without making any explicit assumption about$\backslash$nthe shape of the distribution. For this part, experiments on real data$\backslash$nare reported},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Schuster, M. and Paliwal, K.K.},
doi = {10.1109/78.650093},
eprint = {arXiv:1011.1669v3},
file = {:home/demetres/Downloads/00650093.pdf:pdf},
isbn = {1053-587X},
issn = {1053-587X},
journal = {IEEE Transactions on Signal Processing},
number = {11},
pages = {2673--2681},
pmid = {25246403},
title = {{Bidirectional recurrent neural networks}},
volume = {45},
year = {1997}
}
@article{Bahdanau,
abstract = {Many of the current state-of-the-art Large Vocabulary Continuous Speech Recognition Systems (LVCSR) are hybrids of neural networks and Hidden Markov Models (HMMs). Most of these systems contain separate components that deal with the acoustic modelling, language modelling and sequence decoding. We investigate a more direct approach in which the HMM is replaced with a Recurrent Neural Network (RNN) that performs sequence prediction directly at the character level. Alignment between the input features and the desired character sequence is learned automatically by an attention mechanism built into the RNN. For each predicted character, the attention mechanism scans the input sequence and chooses relevant frames. We propose two methods to speed up this operation: limiting the scan to a subset of most promising frames and pooling over time the information contained in neighboring frames, thereby reducing source sequence length. Integrating an n-gram language model into the decoding process yields recognition accuracies similar to other HMM-free RNN-based approaches.},
archivePrefix = {arXiv},
arxivId = {1508.04395},
author = {Bahdanau, Dzmitry and Chorowski, Jan and Serdyuk, Dmitriy and Brakel, Philemon and Bengio, Yoshua},
eprint = {1508.04395},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bahdanau et al. - Unknown - END-TO-END ATTENTION-BASED LARGE VOCABULARY SPEECH RECOGNITION(2).pdf:pdf},
keywords = {ASR,Index Terms— neural networks,LVCSR,attention,speech recognition},
month = {aug},
title = {{End-to-End Attention-based Large Vocabulary Speech Recognition}},
url = {https://arxiv.org/pdf/1508.04395.pdf},
year = {2015}
}
@article{Doesburg2016,
abstract = {Synchronization of oscillations among brain areas is understood to mediate network communication supporting cognition, perception, and language. How task-dependent synchronization during word production develops throughout childhood and adolescence, as well as how such network coherence is related to the development of language abilities, remains poorly understood. To address this, we recorded magnetoencephalography while 73 participants aged 4–18 years performed a verb generation task. Atlas-guided source reconstruction was performed, and phase synchronization among regions was calculated. Task-dependent increases in synchronization were observed in the theta, alpha, and beta frequency ranges, and network synchronization differences were observed between age groups. Task-dependent synchronization was strongest in the theta band, as were differences between age groups. Network topologies were calculated for brain regions associated with verb generation and were significantly associated with both age and language abilities. These findings establish the maturational trajectory of network synchronization underlying expressive language abilities throughout childhood and adolescence and provide the first evidence for an association between large-scale neurophysiological network synchronization and individual differences in the development of language abilities.},
annote = {NULL},
author = {Doesburg, Sam M. and Tingling, Keriann and MacDonald, Matt J. and Pang, Elizabeth W.},
doi = {10.1162/jocn\_a\_00879},
file = {:home/demetres/Downloads/jocn{\_}a{\_}00879.pdf:pdf},
journal = {Journal of Cognitive Neuroscience},
month = {jan},
number = {1},
pages = {55--68},
title = {{Development of Network Synchronization Predicts Language Abilities}},
url = {http://arxiv.org/abs/1511.04103},
volume = {28},
year = {2016}
}
@article{Hillis,
abstract = {A traditional method of localizing brain functions has been to identify shared areas of brain damage in individuals who have a particular deficit. The rationale of this 'lesion overlap' approach is straightforward: if the individuals can no longer perform the function, the area of brain damaged in most of these individuals must have been responsible for that function. However, the reciprocal association, i.e. the probability of the lesion causing the deficit, is often not evaluated. In this study, we illustrate potential weaknesses of this approach, by re-examining regions of the brain essential for orchestrating speech articulation. A particularly elegant and widely cited lesion overlap study identified the superior part of the precentral gyrus of the insula (in the anterior insula) as the shared area of damage in chronic stroke patients with 'apraxia of speech', a disorder of motor planning and programming of speech. Others have confirmed that patients with apraxia of speech commonly have damage to the anterior insula. However, this reliable association might reflect the vulnerability of the insula to damage following occlusion or narrowing of the middle cerebral artery (which can independently cause apraxia of speech and many other deficits). To evaluate this possibility, we examined the relationship between apraxia of speech and the insula in three unique ways: (i) we determined the probability of the lesion causing the deficit, as well as the deficit being associated with the lesion, by examining speech articulation and advanced MRIs in two consecutive series of patients with acute left hemisphere, non-lacunar stroke, 40 with and 40 without insular damage; (ii) we studied patients at stroke onset to identify the deficit before it resolved in cases of small stroke; and (iii) we identified regions of dysfunctional brain tissue, as well as structural damage. Using this approach, we found no association between apraxia of speech and lesions of the left insula, anterior insula or superior tip of the precentral gyrus of the insula. Instead, in patients with and without insular lesions, apraxia of speech was associated with structural damage or low blood flow in left posterior inferior frontal gyrus. These results illustrate a potential limitation of lesion overlap studies, and illustrate an alternative method for identifying brain-behaviour relationships.},
author = {Hillis, Argye E and Work, Melissa and Barker, Peter B and Jacobs, Michael A and Breese, Elisabeth L and Maurer, Kristin},
doi = {10.1093/brain/awh172},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hillis et al. - Unknown - Re-examining the brain regions crucial for orchestrating speech articulation.pdf:pdf},
isbn = {0006-8950 (Print)$\backslash$n0006-8950 (Linking)},
issn = {00068950},
journal = {Brain},
keywords = {Acute stroke,Aphasia,Apraxia,Insula,Magnetic resonance perfusion imaging},
number = {7},
pages = {1479--1487},
pmid = {15090478},
title = {{Re-examining the brain regions crucial for orchestrating speech articulation}},
volume = {127},
year = {2004}
}
@article{Pereyra2017,
  author    = {Gabriel Pereyra and
               George Tucker and
               Jan Chorowski and
               Lukasz Kaiser and
               Geoffrey E. Hinton},
  title     = {Regularizing Neural Networks by Penalizing Confident Output Distributions},
  journal   = {CoRR},
  volume    = {abs/1701.06548},
  year      = {2017},
  url       = {http://arxiv.org/abs/1701.06548},
  archivePrefix = {arXiv},
  eprint    = {1701.06548},
  timestamp = {Wed, 07 Jun 2017 14:42:24 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/PereyraTCKH17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Clevert,
  author    = {Djork{-}Arn{\'{e}} Clevert and
               Thomas Unterthiner and
               Sepp Hochreiter},
  title     = {Fast and Accurate Deep Network Learning by Exponential Linear Units
               (ELUs)},
  journal   = {CoRR},
  volume    = {abs/1511.07289},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.07289},
  archivePrefix = {arXiv},
  eprint    = {1511.07289},
  timestamp = {Wed, 07 Jun 2017 14:40:17 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ClevertUH15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Yosinski2015,
  author    = {Jason Yosinski and
               Jeff Clune and
               Anh Mai Nguyen and
               Thomas J. Fuchs and
               Hod Lipson},
  title     = {Understanding Neural Networks Through Deep Visualization},
  journal   = {CoRR},
  volume    = {abs/1506.06579},
  year      = {2015},
  url       = {http://arxiv.org/abs/1506.06579},
  archivePrefix = {arXiv},
  eprint    = {1506.06579},
  timestamp = {Wed, 07 Jun 2017 14:41:50 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/YosinskiCNFL15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Kingma2015,
abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
archivePrefix = {arXiv},
arxivId = {1412.6980},
author = {Kingma, Diederik and Ba, Jimmy},
eprint = {1412.6980},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kingma, Ba - 2014 - Adam A Method for Stochastic Optimization.pdf:pdf},
journal = {ICLR},
month = {dec},
title = {{Adam: A Method for Stochastic Optimization}},
url = {http://arxiv.org/abs/1412.6980},
year = {2015}
}
@article{Zhu,
  author    = {Yuke Zhu and
               Oliver Groth and
               Michael S. Bernstein and
               Li Fei{-}Fei},
  title     = {Visual7W: Grounded Question Answering in Images},
  journal   = {CoRR},
  volume    = {abs/1511.03416},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.03416},
  archivePrefix = {arXiv},
  eprint    = {1511.03416},
  timestamp = {Wed, 07 Jun 2017 14:40:06 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ZhuGBF15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@article{Ressel2008,
abstract = {Previous functional magnetic resonance imaging (fMRI) studies investigating hemispheric dominance for language have shown that hemispheric specialization increases with age. We employed magnetoencephalography (MEG) to investigate these effects as a function of normal development. In sum, 22 healthy children aged 7-16 years were investigated using two language tasks: a verb-generation (VG) task and a vowel-identification (VI) task. Significant hemispheric differences were found for both tasks in cerebral language areas using oscillatory MEG spectral analyses, confirming the MEG's ability to detect hemispheric specialization for language in children. Additionally, a significant increase of this lateralization as a function of age was observed for both tasks. As performance in the VI task showed no correlation with age, this increase seems to be unrelated to performance. These results confirm an increase in hemispheric specialization as a function of normal brain maturation. {\textcopyright} 2008 Elsevier Inc. All rights reserved.},
author = {Ressel, Volker and Wilke, Marko and Lidzba, Karen and Lutzenberger, Werner and Kr{\"{a}}geloh-Mann, Ingeborg},
doi = {10.1016/j.bandl.2008.01.004},
file = {:home/demetres/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ressel et al. - 2008 - Increases in language lateralization in normal children as observed using magnetoencephalography.pdf:pdf},
isbn = {1090-2155 (Electronic)$\backslash$r0093-934X (Linking)},
issn = {0093934X},
journal = {Brain and Language},
keywords = {Brain development,Children,Hemispheric dominance,Language development,Language lateralization,Magnetoencephalography},
month = {sep},
number = {3},
pages = {167--176},
pmid = {18279946},
title = {{Increases in language lateralization in normal children as observed using magnetoencephalography}},
volume = {106},
year = {2008}
}
